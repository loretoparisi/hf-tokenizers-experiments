# hf-tokenizers-experiments
Experiments with HuggingFace Tokenizers. Currently we provide customization of the following tokenizers

- SentencePiece BPE Tokenizer


and vocabularies (vocabulary and merge files) for the folliwing models

- [Microsoft Multilingual-MiniLM-L12-H384](https://huggingface.co/microsoft/Multilingual-MiniLM-L12-H384/tree/main)

## How to install
```
git clone https://github.com/loretoparisi/hf-tokenizers-experiments
cd hf-tokenizers-experiments
npm install
```

## How to run
```
cd hf-tokenizers-experiments
cd examples/
node minilm-tokenizer
```
